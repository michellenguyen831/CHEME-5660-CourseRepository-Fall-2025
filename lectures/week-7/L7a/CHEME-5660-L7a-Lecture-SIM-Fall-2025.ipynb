{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f282a53a-ef50-4f6e-a47e-5e36e5cd28a3",
   "metadata": {},
   "source": [
    "# L7a: Introduction to Single Index Models (SIMs)\n",
    "In this lecture, we explore Single Index Models (SIMs) in the context of financial markets. SIMs are a simplified approach to modeling the relationship between a security's returns (growth rate) and the returns (growth rate) of a __market index__.\n",
    "\n",
    "> __Learning Objectives:__\n",
    "> \n",
    "> By the end of this lecture, you will be able to define and demonstrate mastery of the following key concepts:\n",
    "> * __Factor models__ describe the relationship between a security's returns and the returns of a market index, and other factors, such as interest rates, inflation, and economic growth, etc.\n",
    "> * __Single Index Models (SIMs)__ are a type of factor model that simplifies the relationship between a security's returns and the returns of a market index by assuming that the security's returns are linearly related to the returns of the market index.\n",
    "> * __Estimation and evaluation of SIM parameters__ involves estimating the parameters of the model, such as the alpha and beta coefficients, and evaluating the model's performance using statistical measures such as R-squared, and computing the stylized facts of the model.\n",
    "\n",
    "While seemingly simple, SIMs are widely used in portfolio management and risk assessment, as they provide a straightforward way to understand the relationship between a security's returns and the market index. Further, they are a handy way to address the multiasset problem. So let's get started!\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c769b",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "> [▶ Let's compute the optimal weights for a portfolio using the minimum variance portfolio approach](CHEME-5660-L6b-Example-Data-MinVar-Portfolio-Fall-2025.ipynb). In this example, we compute the optimal weights for a portfolio of assets using the minimum variance portfolio approach. We'll compare the performance of this portfolio to an equally weighted portfolio and an index fund, e.g., `SPY`.\n",
    "\n",
    "> [▶ Let's compute the optimal weights for a portfolio using the minimum variance portfolio approach](CHEME-5660-L6b-Example-Data-MinVar-Portfolio-Fall-2025.ipynb). In this example, we compute the optimal weights for a portfolio of assets using the minimum variance portfolio approach. We'll compare the performance of this portfolio to an equally weighted portfolio and an index fund, e.g., `SPY`.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889e12b",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <center>\n",
    "        <img src=\"figs/Fig-MinVar-Portfolio-RA-Schematic.png\" width=\"680\"/>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155903e1",
   "metadata": {},
   "source": [
    "## Concept Review: Data Driven Minimum Variance Portfolio Allocation\n",
    "Last time we introduced Modern Portfolio Theory (MPT) and the concept of minimum variance portfolio allocation. Let's quickly review the key concepts.\n",
    "\n",
    "> __Key Idea:__ The key idea of minimum variance portfolio allocation is to optimally balance risk and reward by diversifying investments across different assets. The minimum variance portfolio is the portfolio that minimizes the overall risk (variance) for a given level of expected (specified) return.\n",
    "\n",
    "Consider a portfolio $\\mathcal{P}$ consisting of $M$ __risky assets__, i.e., only equity, ETFs (or potentially derivatives) but no fixed income assets. In this case, we can formulate the optimization problem for the optimal weights $\\mathbf{w}$ (mixture) as (written in terms of growth rate):\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{align*}\n",
    "\\text{minimize}~\\text{Var}(g_{\\mathcal{P}}) &= \\sum_{i\\in\\mathcal{P}}\\sum_{j\\in\\mathcal{P}}w_{i}w_{j}\\underbrace{\\text{Cov}\\left(g_{i},g_{j}\\right)}_{= \\sigma_{i}\\sigma_{j}\\rho_{ij}}\\quad{\\Longleftrightarrow\\mathbf{w}^\\top \\mathbf{\\Sigma}_{g} \\mathbf{w}} \\\\\n",
    "\\text{subject to}~\\mathbb{E}(g_{\\mathcal{P}})& =  \\sum_{i\\in\\mathcal{P}}w_{i}\\;\\mathbb{E}(g_{i})= R^{*}\\quad\\Longleftrightarrow\\mathbf{w}^\\top \\mathbb{E}(\\mathbf{g}) = R^{*} \\\\\n",
    "\\sum_{i\\in\\mathcal{P}}w_{i} & =  1 \\\\\n",
    "w_{i} & \\geq  0\\quad\\forall{i}\\in\\mathcal{P}\n",
    "\\end{align*}}\n",
    "$$\n",
    "The term $R^{*}$ is the target annualized growth rate (return) for portfolio $\\mathcal{P}$ specified by the investor. The $w_{i}\\geq{0}~\\forall{i}\\in\\mathcal{P}$ and the summation-to-unity constraints forbid short selling (borrowing). If short selling (borrowing) is allowed, these constraints can be relaxed.\n",
    "\n",
    "> __Frontier:__ To construct the efficient frontier, we systematically vary $R^{*}$ and solve the optimization problem for each target return level, generating the set of minimum variance portfolios that trace out the efficient frontier curve. Each point on the frontier is a different set of portfolio weights.\n",
    "\n",
    "Let's solve this problem to get a feel for how it works using an example.\n",
    "\n",
    "> [▶ Let's compute the optimal weights for a portfolio using the minimum variance portfolio approach](CHEME-5660-L6b-Example-Data-MinVar-Portfolio-Fall-2025.ipynb). In this example, we compute the optimal weights for a portfolio of assets using the minimum variance portfolio approach. We'll compare the performance of this portfolio to an equally weighted portfolio and an index fund, e.g., `SPY`.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd217aa-fc94-4758-80b1-8a5d101c83be",
   "metadata": {},
   "source": [
    "## Factor models\n",
    "The idea underlying factor models is that the returns of a security can be explained by a firm specific factor, the returns of a market index, and other factors, such as interest rates, inflation, and economic growth, etc. \n",
    "\n",
    "Suppose the growth of firm $i$ at time $t$ is denoted by $g^{(t)}_{i}$. We can express the growth (return) of firm $i$ at time $t$ as a sum of firm specific growth, the growth of a market index at time $t$, denoted by $g^{(t)}_{M}$, and other factors, such as interest rates, inflation, and economic growth, etc, which we denotes as $\\left\\{f^{(t)}_{1}, f^{(t)}_{2}, \\ldots, f^{(t)}_{k}\\right\\}$:\n",
    "$$\n",
    "g^{(t)}_{i} = \\underbrace{\\alpha_{i}}_{\\text{firm}} + \\underbrace{\\beta_{i}g^{(t)}_{M} }_{\\text{market}}+ \\overbrace{\\sum_{j=1}^{k}\\gamma_{ij}f^{(t)}_{j}}^{\\text{other}} + \\epsilon^{(t)}_{i}\n",
    "$$\n",
    "where $\\alpha_{i}$ is the firm-specific intercept term, $\\beta_{i}$ is the sensitivity of the firms' growth (returns) to the market index, $\\gamma_{ij}$ is the sensitivity of the security's growth (returns) to the $j$-th factor, and $\\epsilon^{(t)}_{i}$ is the error term, which captures fraction of the growth (returns) not explained by the model.\n",
    "\n",
    "### Example: Capital Asset Pricing Model (CAPM)\n",
    "The Capital Asset Pricing Model (CAPM) is a special case of the factor model where the only factor considered is the market index. In this case, the excess growth (returns) of firm $i$ at time $t$ can be expressed as:\n",
    "$$\n",
    "g^{(t)}_{i} - \\bar{r} = \\beta_{i}(g^{(t)}_{M} - \\bar{r}) + \\epsilon^{(t)}_{i}\n",
    "$$\n",
    "where $\\bar{r}$ is the (continuously compounded) risk-free growth rate, $\\beta_{i}$ is the sensitivity of the security's growth (returns) to the market index, and $\\epsilon^{(t)}_{i}$ is the error term (fraction of the growth (returns) not explained by the model).\n",
    "\n",
    "The CAPM assumes that the expected growth (returns) of a firm is linearly related to the expected growth (returns) of the market index, adjusted for the risk-free rate. The term $\\beta_{i}$ measures the sensitivity of the security's growth (returns) to the market index, and it is a measure of systematic risk. \n",
    "\n",
    "The CAPM is a (arguably) the most widely taught single factor model in finance and is used to estimate the expected growth (returns) of a firm based on its risk relative to the market.\n",
    "\n",
    "### Example: The Fama-French Three-Factor Model\n",
    "Aurguably, one of the most widely used factor models in finance is the Fama-French three-factor model.\n",
    "The development of this model began with Fama and French's empirical work in 1992 demonstrating the limitations of Capital Asset Pricing Model (CAPM), followed by their formal introduction of the three-factor model in 1993:\n",
    "\n",
    "> Fama, E. F.; French, K. R. (1992). The Cross-Section of Expected Stock Returns. *The Journal of Finance*, 47(2), 427-465. doi:10.1111/j.1540-6261.1992.tb04398.x\n",
    "> \n",
    "> Fama, E. F.; French, K. R. (1993). Common risk factors in the returns on stocks and bonds. *Journal of Financial Economics*, 33, 3-56. doi:10.1016/0304-405X(93)90023-5\n",
    "\n",
    "\n",
    "The Fama-French model has three specific factors (written in terms of returns): the market factor (similar to our market index $g^{(t)}_{M}$), a size factor that captures the return difference between small-cap and large-cap stocks, and a value factor that captures the return difference between high book-to-market (value) and low book-to-market (growth) stocks. Mathematically, the model can be expressed as:\n",
    "$$\n",
    "r^{(t)}_{i} = \\alpha_{i} + \\beta_{i}r^{(t)}_{M} + s_{i}\\;\\text{SMB}^{(t)} + h_{i}\\;\\text{HML}^{(t)} + \\epsilon^{(t)}_{i},\n",
    "$$\n",
    "where $\\text{SMB}^{(t)}$ represents the _Small Minus Big_ factor (the return of small-cap stocks minus large-cap stocks at time $t$), $\\text{HML}^{(t)}$ represents the _High Minus Low_ factor (the return of high book-to-market stocks minus low book-to-market stocks at time $t$), and $s_{i}$ and $h_{i}$ are the factor loadings that measure firm $i$'s sensitivity to the size and value factors, respectively.\n",
    "\n",
    "> __Succsess!__ Fama and French demonstrated that portfolios formed on size and book-to-market characteristics could explain over 90% of the variation in diversified portfolio returns, compared with the average 70% given by the CAPM. However, this comes at a cost: the Fama-French model is more complex and requires estimating additional factors, and more parameters, which can introduce estimation error.\n",
    "\n",
    "For us, we are going to use the Farma-French model, but only including the market factor. This is known as a __Single Index Model (SIM)__.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34938e8",
   "metadata": {},
   "source": [
    "## Single Index Models (SIMs)\n",
    "Single index models are factor models that consider only the return (growth) of the market factor. These models were originaly developed by Sharpe, 1963: [Sharpe, William F. (1963). \"A Simplified Model for Portfolio Analysis\". Management Science, 9(2): 277-293. doi:10.1287/mnsc.9.2.277.](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.9.2.277)\n",
    "\n",
    "Suppose the growth of firm $i$ at time $t$ is denoted by $g^{(t)}_{i}$. Then, the single index model of the return (growth rate) is given by:\n",
    "$$\n",
    "g^{(t)}_{i} = \\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i},\n",
    "$$\n",
    "where $\\alpha_{i}$ is the _idosyncratic (firm-specific) growth_, $\\beta_{i}$ is the component of the growth rate of firm $i$ explained by the market (it is also a measure of risk), and $\\epsilon^{(t)}_{i}$ denotes an error model associated with firm $i$ (describes growth rate not captured by the firm or market factors). \n",
    "\n",
    "> __Aside: Return versus Growth?__\n",
    ">\n",
    "> Sharpe's original model used the return, and not the growth rate. What is the connection between the two models? Let's start from the original return model, and show how it relates to the growth model. The original model is given by:\n",
    "> $$\n",
    "> \\begin{align*}\n",
    "> r^{(t)}_{i} &= \\alpha_{i} + \\beta_{i}\\;r^{(t)}_{M} + \\epsilon^{(t)}_{i}\\\\\n",
    "> \\end{align*}\n",
    "> $$\n",
    "> where $r^{(t)}_{i}$ is the return of firm $i$ at time $t$, $r^{(t)}_{M}$ is the return of the market index at time $t$, $\\alpha_{i}$ is the idiosyncratic return of firm $i$, $\\beta_{i}$ is the sensitivity of the return of firm $i$ to the return of the market index, and $\\epsilon^{(t)}_{i}$ is the error model associated with firm $i$.\n",
    "> However, the growth rate and the return are related through the time step:  $r^{(t)}_{i} = g^{(t)}_{i}\\;\\Delta{t}$. Thus, we can rewrite the original model as:\n",
    "> $$\n",
    "> \\begin{align*}\n",
    "> \\overbrace{g^{(t)}_{i}\\;\\Delta{t}}^{r^{(t)}_{i}} &= \\alpha_{i} + \\beta_{i}\\;(\\overbrace{g^{(t)}_{M}\\;\\Delta{t}}^{r^{(t)}_{M}}) + \\epsilon^{(t)}_{i}\\quad\\Longrightarrow\\text{Divide by }\\;\\Delta{t}\\\\\n",
    "> g^{(t)}_{i} &= \\underbrace{\\frac{\\alpha_{i}}{\\Delta{t}}}_{\\bar{\\alpha}_{i}} + {\\beta_{i}}\\;g^{(t)}_{M} + \\underbrace{\\frac{\\epsilon^{(t)}_{i}}{\\Delta{t}}}_{\\bar{\\epsilon}^{(t)}_{i}}\\\\\n",
    "g^{(t)}_{i} &= \\bar{\\alpha}_{i}+ \\beta_{i}\\;g^{(t)}_{M} + \\bar{\\epsilon}^{(t)}_{i}\\\\\n",
    "> \\end{align*}\n",
    "> $$\n",
    "> Thus, the two models have the same form, but the $\\alpha_{i}$ parameter, and the error model $\\epsilon^{(t)}_{i}$ are divided by the time step $\\Delta{t}$. In practice, __we drop the overbar__ on $\\alpha_{i}$ and $\\epsilon^{(t)}_{i}$, which gives the growth rate SIM:\n",
    "> $$\n",
    "> \\boxed{\n",
    "> g^{(t)}_{i} = \\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}\\quad\\blacksquare\n",
    ">}\n",
    "> $$\n",
    "> By default, we'll use the growth model, but you should be aware of the original return model, and how it relates to the growth model.\n",
    "\n",
    "### What do the $(\\alpha_{i}, \\beta_{i})$ parameters mean?\n",
    "The parameters of the single index model have some interesting interpretations.\n",
    "\n",
    "> __Parameter Interpretations:__\n",
    ">\n",
    "> * The $\\alpha_{i}$ parameter is the idiosyncratic (firm-specific) growth (return), which captures the growth rate (return) of firm $i$ that is __not__ explained by the market index. \n",
    "> * The $\\beta_{i}$ parameter has two meanings: it is a measure of the the growth rate (return) of firm $i$ explained by the market index, and it is also a measure of risk. A higher $\\beta_{i}$ indicates that the growth rate (return) of firm $i$ is more sensitive to changes in the market index, and thus, it is more risky. \n",
    "\n",
    "Let's dig into the meaning of the $\\beta_{i}$ parameter a little more, starting with the growth interpretation. We can rearrance the SIM as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "g^{(t)}_{i} &= \\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}\\\\\n",
    "g^{(t)}_{i} - \\alpha_{i} - \\epsilon^{(t)}_{i} &= \\beta_{i}\\;g^{(t)}_{M}\\\\\n",
    "\\underbrace{\\frac{g^{(t)}_{i} - \\alpha_{i} - \\epsilon^{(t)}_{i}}{g^{(t)}_{M}}}_{\\text{fraction explained by market}} &= \\beta_{i}\\quad\\blacksquare\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "The __risk interpretation__ of $\\beta$ is a more subtle. To understand this, let's start by taking the variance of both sides of the SIM:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Var}\\left(g^{(t)}_{i}\\right) &= \\operatorname{Var}\\left(\\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}\\right)\\quad\\Longrightarrow\\operatorname{Var}(a+b+c) = \\operatorname{Var}(a) + \\operatorname{Var}(b) + \\operatorname{Var}(c)\\;\\;\\text{if independent}\\\\\n",
    "&= \\operatorname{Var}\\left(\\alpha_{i}\\right) + \\operatorname{Var}\\left(\\beta_{i}\\;g^{(t)}_{M}\\right) + \\operatorname{Var}\\left(\\epsilon^{(t)}_{i}\\right)\\\\\n",
    "&= 0 + \\beta_{i}^{2}\\;\\operatorname{Var}\\left(g^{(t)}_{M}\\right) + \\operatorname{Var}\\left(\\epsilon^{(t)}_{i}\\right)\\\\\n",
    "\\sigma_{i}^{2} &= \\beta_{i}^{2}\\;\\sigma_{M}^{2} + \\sigma_{\\epsilon,i}^{2}\\quad\\blacksquare\n",
    "\\end{align*}\n",
    "$$\n",
    "where we used the fact that $\\alpha_{i}$ is a constant (variance is zero), $\\beta_{i}$ is a constant that can be factored out of the variance, and we assume that the error term $\\epsilon^{(t)}_{i}$ is uncorrelated with the market growth $g^{(t)}_{M}$. \n",
    "\n",
    "> __Risk__: The total risk of firm $i$ (measured by $\\sigma_{i}^{2}$) consists of two components:  __Systematic risk__: $\\beta_{i}^{2}\\;\\sigma_{M}^{2}$ and __Idiosyncratic risk__: $\\sigma_{\\epsilon,i}^{2}$.\n",
    "> The systematic risk is the risk that comes from exposure to market movements, while the idiosyncratic risk is the firm-specific risk that is independent of the market.\n",
    "\n",
    "Now, to derive the formula for $\\beta_{i}$, we need to use the covariance relationship. Taking the covariance of both sides of the SIM with the market growth $g^{(t)}_{M}$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Cov}\\left(g^{(t)}_{i}, g^{(t)}_{M}\\right) &= \\text{Cov}\\left(\\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}, g^{(t)}_{M}\\right)\\\\\n",
    "&= \\text{Cov}\\left(\\alpha_{i}, g^{(t)}_{M}\\right) + \\text{Cov}\\left(\\beta_{i}\\;g^{(t)}_{M}, g^{(t)}_{M}\\right) + \\text{Cov}\\left(\\epsilon^{(t)}_{i}, g^{(t)}_{M}\\right)\\\\\n",
    "&= 0 + \\beta_{i}\\;\\text{Cov}\\left(g^{(t)}_{M}, g^{(t)}_{M}\\right) + 0\\\\\n",
    "&= \\beta_{i}\\;\\text{Var}\\left(g^{(t)}_{M}\\right)\\\\\n",
    "\\text{Cov}\\left(g^{(t)}_{i}, g^{(t)}_{M}\\right) &= \\beta_{i}\\;\\sigma_{M}^{2}\\quad\\Longrightarrow\\text{solve for }\\beta_{i}\\\\\n",
    "\\beta_{i} &= \\frac{\\text{Cov}\\left(g^{(t)}_{i}, g^{(t)}_{M}\\right)}{\\text{Var}\\left(g^{(t)}_{M}\\right)} = \\frac{\\text{Cov}\\left(g_{i}, g_{M}\\right)}{\\text{Var}\\left(g_{M}\\right)}\\quad\\blacksquare\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "> __Beta:__\n",
    "> The $\\beta_{i}$ parameter measures how much systematic risk the firm carries relative to the market. \n",
    "> * If $\\beta_{i} = 1$, the firm moves in lockstep with the market. \n",
    "> * If $\\beta_{i} > 1$, the firm is more volatile than the market (amplifies market movements). \n",
    "> * If $\\beta_{i} < 1$, the firm is less volatile than the market (dampens market movements).\n",
    "\n",
    "Wow! That's pretty cool! But, how do we estimate the parameters of the SIM? Let's take a look at that next.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bd1ba",
   "metadata": {},
   "source": [
    "## Estimation of SIM parameters\n",
    "We can estimate the single index model parameters from historical data. The most common method is to use __regularized ordinary least squares (OLS)__ regression, which minimizes the sum of squared errors between the observed growth rates and the predicted growth rates from the SIM. \n",
    "\n",
    "Suppose we have a set of __market observations__ of the growth rate of firm $i$ which we pack into the vector $\\mathbf{y} = \\left\\{g^{(2)}_{i},g^{(3)}_{i},\\ldots\\right\\}$, where the superscript denotes the time period (e.g., day, month, quarter, year, etc) and the subscript denotes the firm index. Further, suppose we have a set of __market observations__ of the growth rate of the market index which we pack into the vector $\\mathbf{g}_{M} = \\left\\{g^{(2)}_{M},g^{(3)}_{M},\\ldots\\right\\}$.\n",
    "\n",
    "The single index model tells us that each observation can be written as:\n",
    "$$\n",
    "g^{(t)}_{i} = \\alpha_{i} + \\beta_{i}\\;g^{(t)}_{M} + \\epsilon^{(t)}_{i}\n",
    "$$\n",
    "We can express this in matrix form by creating the design matrix $\\hat{\\mathbf{X}}$, which contains a column of ones (for the intercept term $\\alpha_i$) and the market growth rates $g^{(t)}_{M}$ as the second column, where each row corresponds to a different time period. Then our single index model in matrix vector form becomes:\n",
    "$$\n",
    "\\mathbf{y} = \\hat{\\mathbf{X}}\\;\\boldsymbol{\\theta} + \\boldsymbol{\\varepsilon}\n",
    "$$\n",
    "where $\\boldsymbol{\\theta} = (\\alpha_{i},\\beta_{i})^{\\top}$ are the true parameters and $\\boldsymbol{\\varepsilon} = \\left\\{\\epsilon^{(2)}_{i},{\\epsilon}^{(3)}_{i},\\ldots,\\epsilon^{(T)}_{i}\\right\\}^{\\top}$ is the vector of error terms. \n",
    "\n",
    "> __Single Index Model Parameter Estimation__\n",
    ">\n",
    "> The single index model parameters $\\boldsymbol{\\theta}_{i} = (\\alpha_{i},\\beta_{i})$ for each firm $i$ are estimated by solving the regularized linear regression problem:\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\hat{\\boldsymbol{\\theta}} = \\arg\\min_{\\boldsymbol{\\theta}}\\left( \\frac{1}{2}\\;\\lVert~\\mathbf{y} - \\hat{\\mathbf{X}}\\;\\boldsymbol{\\theta}~\\rVert^{2}_{2} + \\frac{\\delta}{2}\\;\\lVert~\\boldsymbol{\\theta}~\\rVert^{2}_{2}\\right)\n",
    "\\end{align*}\n",
    "> $$\n",
    "> where $\\delta$ is a regularization parameter that controls the amount of shrinkage applied to the parameter estimates, and $\\lVert~\\cdot~\\rVert^{2}_{2}$ is the squared $l_2$ norm. The minimum-norm solution to the parameter estimation problem is given by:\n",
    "> $$\n",
    "\\boxed{\n",
    "\\begin{align*}\n",
    "    \\hat{\\boldsymbol{\\theta}} &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\mathbf{y}\\quad\\blacksquare\n",
    "\\end{align*}\n",
    "}\n",
    "$$\n",
    "\n",
    "Let's explore how our parameter estimates $\\hat{\\boldsymbol{\\theta}}$ relate to the true (but unknown) parameters $\\boldsymbol{\\theta}$. Substitute the true model $\\mathbf{y} = \\hat{\\mathbf{X}}\\;\\boldsymbol{\\theta} + \\boldsymbol{\\varepsilon}$ into our solution:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{\\boldsymbol{\\theta}} &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\left(\\hat{\\mathbf{X}}\\;\\boldsymbol{\\theta} + \\boldsymbol{\\varepsilon}\\right)\\\\\n",
    "    &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}\\;\\boldsymbol{\\theta} + \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\boldsymbol{\\varepsilon}\\\\\n",
    "    &= \\underbrace{\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}}_{\\text{Shrinkage matrix}\\;\\mathbf{S}}\\;\\boldsymbol{\\theta} + \\underbrace{\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}}_{\\text{Error propagation}}\\boldsymbol{\\varepsilon}\\\\\n",
    "    \\hat{\\boldsymbol{\\theta}} &= \\mathbf{S}\\;\\boldsymbol{\\theta} + \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\boldsymbol{\\varepsilon}\\quad\\blacksquare\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This decomposition is __not__ used for computation (since we don't know the true $\\boldsymbol{\\theta}$), but rather for __theoretical analysis__ of our estimator's properties. It reveals two key insights:\n",
    "\n",
    "1. **Bias**: When $\\delta > 0$, we have $\\mathbf{S} \\neq \\mathbf{I}$, so $\\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] = \\mathbf{S}\\;\\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta}$. This means our estimator is biased, but the bias trades off against reduced variance.\n",
    "\n",
    "2. **Variance**: The second term shows how the random errors $\\boldsymbol{\\varepsilon}$ propagate to our estimates. Regularization ($\\delta > 0$) reduces the variance of this term compared to ordinary least squares.\n",
    "\n",
    "However, we don't know the true parameters! So how do we assess the quality of our estimates? How much uncertainty is there in our estimates? Let's explore that next.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57808cc5",
   "metadata": {},
   "source": [
    "## Error Analysis and Uncertainty Quantification\n",
    "We assume the error model $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0},\\Delta{t}\\;\\sigma^{2}\\;\\mathbf{I})$, where $\\sigma^{2}$ is the variance of the error model. Of course, we don't know $\\sigma^{2}$, so we need to estimate it from the data. A common approach is to use estimate the variance of the residuals:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}^{2} &= \\frac{1}{\\Delta{t}(n-p)}\\;\\lVert~\\underbrace{\\mathbf{y} - \\hat{\\mathbf{X}}\\;\\hat{\\boldsymbol{\\theta}}}_{\\text{residual}\\;\\mathbf{r}}~\\rVert^{2}_{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $n$ is the number of training examples, $p = 2$ is the number of model parameters (including the intercept), and $\\hat{\\boldsymbol{\\theta}}$ is the estimated parameter vector.\n",
    "\n",
    "### Theoretical Parameter uncertainty estimation\n",
    "To quantify the uncertainty in our parameter estimates $\\hat{\\boldsymbol{\\theta}} = (\\hat{\\alpha}_{i}, \\hat{\\beta}_{i})^{\\top}$, we need to derive the distribution of our estimator. Starting from our estimator formula and the bias-variance decomposition we derived earlier:\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\theta}} = \\mathbf{S}\\;\\boldsymbol{\\theta} + \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\boldsymbol{\\varepsilon}\n",
    "$$\n",
    "where $\\mathbf{S} = \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}$ is the shrinkage matrix. Since $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0},\\Delta{t}\\;\\sigma^{2}\\;\\mathbf{I})$, the second term is a linear transformation of a Normal random vector. \n",
    "\n",
    "\n",
    "> __Theory__\n",
    "> \n",
    "> For any matrix $\\mathbf{A}$ and Normal vector $\\mathbf{z} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, we have $\\mathbf{A}\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{A}\\boldsymbol{\\mu}, \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^{\\top})$, where $\\boldsymbol{\\mu}$ is the mean vector and $\\boldsymbol{\\Sigma}$ is the covariance matrix of the vector $\\mathbf{z}$.\n",
    " > Applying this property with $\\mathbf{A} = \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}$ gives us:\n",
    "> $$\n",
    "> \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}\\left(\\mathbf{0}, \\Delta{t}\\;\\sigma^2\\;\\mathbf{A}\\mathbf{A}^{\\top}\\right)\n",
    "> $$\n",
    "> Now we compute the matrix product $\\mathbf{A}\\mathbf{A}^{\\top}$:\n",
    "> $$\n",
    ">\\begin{align*}\n",
    ">\\mathbf{A}\\mathbf{A}^{\\top} &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}}\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\quad\\Longrightarrow\\text{Algebra!}\\\\\n",
    ">\\mathbf{A}\\mathbf{A}^{\\top} &= \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\quad\\blacksquare\n",
    ">\\end{align*}\n",
    "> $$\n",
    " > Therefore, our parameter estimator has the distribution:\n",
    "> $$\n",
    "> \\boxed{\n",
    "> \\hat{\\boldsymbol{\\theta}} \\sim \\mathcal{N}\\left(\\mathbf{S}\\;\\boldsymbol{\\theta}, \\Delta{t}\\;\\sigma^2\\;\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\right)\\quad\\blacksquare}\n",
    "> $$\n",
    "> For practical confidence interval construction, we often approximate this as:\n",
    "> $$\n",
    "> \\hat{\\boldsymbol{\\theta}} \\sim \\mathcal{N}\\left(\\boldsymbol{\\theta}, \\Delta{t}\\;\\sigma^2\\;\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\right)\n",
    "> $$\n",
    "> This approximation assumes that the bias introduced by the shrinkage matrix $\\mathbf{S}$ is negligible for inference purposes, which is reasonable when the regularization parameter $\\delta$ is small.\n",
    "\n",
    "The covariance matrix of our parameter estimates is:\n",
    "$$\n",
    "\\text{Cov}(\\hat{\\boldsymbol{\\theta}}) = \\Delta{t}\\;\\hat{\\sigma}^2\\;\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\n",
    "$$\n",
    "where $\\hat{\\sigma}^2$ is our estimated error variance. This gives us the standard errors for each parameter:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{SE}(\\hat{\\alpha}_{i}) &= \\sqrt{\\Delta{t}\\;\\hat{\\sigma}^2\\;\\left[\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\right]_{1,1}}\\quad\\text{and}\\quad\n",
    "\\text{SE}(\\hat{\\beta}_{i}) = \\sqrt{\\Delta{t}\\;\\hat{\\sigma}^2\\;\\left[\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\right]_{2,2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "which we can use to construct confidence intervals for our parameters. For a $(1-\\alpha)\\%$ confidence interval:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\alpha}_{i} &\\pm t_{\\alpha/2,n-p}\\;\\text{SE}(\\hat{\\alpha}_{i})\\quad\\text{and}\\quad\n",
    "\\hat{\\beta}_{i} \\pm t_{\\alpha/2,n-p}\\;\\text{SE}(\\hat{\\beta}_{i})\n",
    "\\end{align*}\n",
    "$$\n",
    "where $t_{\\alpha/2,n-p}$ is the critical value from the t-distribution with $n-p$ degrees of freedom.\n",
    "\n",
    "> __Testing the market relationship:__\n",
    "> A particularly important hypothesis test in finance is whether $\\beta_{i} = 1$, which would indicate that the firm moves exactly in lockstep with the market. We can test this using the t-statistic:\n",
    "> $$\n",
    "> t = \\frac{\\hat{\\beta}_{i} - 1}{\\text{SE}(\\hat{\\beta}_{i})}\n",
    "> $$\n",
    "> If $|t| > t_{\\alpha/2,n-p}$, we reject the null hypothesis that $\\beta_{i} = 1$ at the $\\alpha$ significance level. Similarly, we can test whether $\\alpha_{i} = 0$ (no excess return beyond market exposure) using:\n",
    "> $$\n",
    "> t = \\frac{\\hat{\\alpha}_{i}}{\\text{SE}(\\hat{\\alpha}_{i})}\n",
    "> $$\n",
    "\n",
    "\n",
    "### Simulation-based validation of theoretical results\n",
    "An interesting way to validate our theoretical distributional result is through Monte Carlo simulation. The idea is to use our estimated parameters and error model to generate many __synthetic datasets__, then examine the empirical distribution of parameter estimates that we obtain from these datasets. This allows us to see if the empirical results match our theoretical expectations.\n",
    "\n",
    "Let's look at some pseudocode for how we might implement this simulation.\n",
    "\n",
    "__Initialization:__ Given the design matrix $\\hat{\\mathbf{X}}$, the estimated parameters $\\hat{\\boldsymbol{\\theta}}$ and the error variance $\\hat{\\sigma}^2$ from our real data, a value for the regularization parameter $\\delta\\geq{0}$ and the number of samples to generate $K$. We also need to estimate\n",
    "\n",
    "For each $k = 1, 2, \\ldots, K$: __do__:\n",
    "1. Generate synthetic errors: $\\boldsymbol{\\varepsilon}^{(k)} \\sim \\mathcal{N}(\\mathbf{0}, \\Delta{t}\\;\\hat{\\sigma}^2\\;\\mathbf{I})$\n",
    "2. Create synthetic observations: $\\mathbf{y}^{(k)} \\gets \\hat{\\mathbf{X}}\\;\\hat{\\boldsymbol{\\theta}} + \\boldsymbol{\\varepsilon}^{(k)}$\n",
    "3. Estimate parameters from the synthetic observation: $\\hat{\\boldsymbol{\\theta}}^{(k)} \\gets \\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\\hat{\\mathbf{X}}^{\\top}\\mathbf{y}^{(k)}$\n",
    "\n",
    "Analyze the empirical distribution of $\\left\\{\\hat{\\boldsymbol{\\theta}}^{(1)}, \\hat{\\boldsymbol{\\theta}}^{(2)}, \\ldots, \\hat{\\boldsymbol{\\theta}}^{(K)}\\right\\}$. The empirical mean and covariance of the simulated parameter estimates should approximate our theoretical result:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Empirical mean} &\\approx \\mathbf{S}\\;\\hat{\\boldsymbol{\\theta}}\\\\\n",
    "\\text{Empirical covariance} &\\approx \\Delta{t}\\;\\hat{\\sigma}^2\\;\\left(\\hat{\\mathbf{X}}^{\\top}\\hat{\\mathbf{X}} + \\delta\\;\\mathbf{I}\\right)^{-1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This simulation approach validates our theoretical distributional results by showing that the actual variability matches our mathematical predictions when we repeat the estimation procedure many times with different random error realizations. Practically, this creates a parametric bootstrap sampler that allows us to generate synthetic datasets for uncertainty quantification and risk assessment.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ae3f2",
   "metadata": {},
   "source": [
    "## Evaluation of SIM performance\n",
    "Once we have estimated the SIM parameters, we need to evaluate how well our model fits the data and quantify the uncertainty in our parameter estimates. Lastly, we evaluate the stylized facts of the model, which are the key properties that we expect our model to satisfy.\n",
    "\n",
    "> __Understanding model fit and uncertainty:__\n",
    "> The uncertainty estimates help us understand the reliability of our risk and return predictions. For instance, when using $\\hat{\\beta}_{i}$ to estimate systematic risk, the confidence interval tells us the range of plausible risk levels. This is crucial for portfolio construction and risk management, where overconfidence in parameter estimates can lead to suboptimal decisions. \n",
    "> \n",
    ">Moreover, firms with high parameter uncertainty (wide confidence intervals) may require different treatment in portfolio optimization compared to firms with precisely estimated parameters. The error model thus provides essential information for robust financial decision-making under uncertainty.\n",
    "\n",
    "### Coefficient of determination (R-squared)\n",
    "The most common measure of model fit is the coefficient of determination, $R^2$, which tells us what fraction of the variance in the firm's growth rate is explained by the market index:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}} = 1 - \\frac{\\sum_{t=2}^{T}\\left(\\mu^{(t)}_{i} - \\hat{\\mu}^{(t)}_{i}\\right)^2}{\\sum_{t=2}^{T}\\left(\\mu^{(t)}_{i} - \\mu^{\\prime}_{i}\\right)^2}\n",
    "$$\n",
    "where $\\hat{\\mu}^{(t)}_{i} = \\hat{\\alpha}_{i} + \\hat{\\beta}_{i}\\;\\mu^{(t)}_{M}$ is the predicted growth rate from our model, and $\\mu^{\\prime}_{i}$ is the sample mean of the firm's growth rates. An $R^2$ close to 1 indicates that the market index explains most of the firm's growth rate variation, while an $R^2$ close to 0 suggests weak market correlation.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f635b1",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team. \n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. Such decisions should be based solely on evaluating your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs.\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
